{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. Deep Learning Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go into deep learning modelling, we will first need to have a quick familiarisation with a deep learning framework. We recommend __[Keras](https://keras.io)__, which is built on top of Tensorflow, but alternatively, you can consider __[PyTorch](https://pytorch.org)__. Resources are abundant online on how to use them, but here are some official guides to get you started:\n",
    "- PyTorch has a [60 Minute Blitz Guide](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html)\n",
    "- Tensorflow has an [Intro to Keras guide](https://www.tensorflow.org/guide/keras)\n",
    "\n",
    "A few words on the difference between Keras and PyTorch - Keras is a high level wrapper on top of Google's Tensorflow, the most popular deep learning framework out there. Being more low level, Tensorflow faces many issues and troubles, which are addressed by the abstractions of Keras, making it a great way to start. Facebook's PyTorch on the other hand is a newcomer which has received massive interest in recent years, and is playing catch up to Tensorflow/Keras.\n",
    "\n",
    "If you are more interested in how deep learning software has evolved since the days of Caffe and Theano as well as more in depth into what is happening in the software behind the scenes, we also recommend a [full lecture from Stanford](https://www.youtube.com/watch?v=6SlgtELqOWc) on this topic, although this is extra knowledge that isn't fully critical to this week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base on the tutorials you go through, you should be ready to build a 2 (or more) layer Multi-Level Perceptron (MLP) with deep learning. With the dataset you have prepared your machine learning model in the previous section, run your data through a MLP model with `Dense` (`Linear`) layers instead. Do some slight model adjustments, and discuss what kind of adjustments lead to improvements in score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from src.load_img import LoadImage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "imgloader = LoadImage()\n",
    "imgloader.load_unpickledata()\n",
    "train_data,train_labels,test_data,test_labels=imgloader.getData()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data transformations/preprocessing\n",
    "\n",
    "Most neural networks expect the images of a fixed size. Therefore, you will need to write some prepocessing code. At the basic level, you will need to normalise the data. Use the appropriate data generator/loader methods to encapsulate your data for training purposes. Do the same for both the train and test (and val, if exist) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Normalizing Image Data__\n",
    "- Instead of standard scaling, which will result in negative values.\n",
    "- Since we know image pixels are bounded by 0-255 range, we normalize them between this range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data/255\n",
    "test_data=test_data/255\n",
    "n_classes = 10\n",
    "train_labels = keras.utils.to_categorical(train_labels, n_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test= train_test_split(train_data,train_labels,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Build multi-layer perceptron neural network models with Keras \n",
    "\n",
    "The Keras Python library for deep learning focuses on the creation of models as a sequence of layers.\n",
    "\n",
    "In here, you will discover the simple components that you can use to create neural networks and simple deep learning models using Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "numofFeatures=train_data.shape[1]\n",
    "model=Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(numofFeatures,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the MLP network in CIFAR-10\n",
    "\n",
    "The main objective is to train the MLP network to achieve a balance between the ability to respond correctly to the input patterns that are used for training and the ability to provide good response to the input that is similar. Use the stochastic gradient descent optimiser with an appropriate learning rate between 1e-2 and 1e-3. Report your evaluation loss and accuracy, and you can also consider doing things like early stopping to prevent overfitting and achieve the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "37500/37500 [==============================] - 6s 166us/step - loss: 2.3025 - acc: 0.0981 - val_loss: 2.3031 - val_acc: 0.1011\n",
      "Epoch 2/3\n",
      "37500/37500 [==============================] - 6s 165us/step - loss: 2.3020 - acc: 0.1014 - val_loss: 2.3024 - val_acc: 0.1018\n",
      "Epoch 3/3\n",
      "37500/37500 [==============================] - 6s 164us/step - loss: 2.3019 - acc: 0.1008 - val_loss: 2.3031 - val_acc: 0.1015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbeabe05128>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=3, validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.6725511363983154\n",
      "Test accuracy: 0.396\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(test_data, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Batch Size__ <br>\n",
    "-Increaseing the batch size, gives a boost in the val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "37500/37500 [==============================] - 156s 4ms/step - loss: 2.3263 - acc: 0.0980 - val_loss: 2.3106 - val_acc: 0.1010\n",
      "Epoch 2/3\n",
      "37500/37500 [==============================] - 153s 4ms/step - loss: 2.3243 - acc: 0.0989 - val_loss: 2.3163 - val_acc: 0.0970\n",
      "Epoch 3/3\n",
      "37500/37500 [==============================] - 164s 4ms/step - loss: 2.3225 - acc: 0.1011 - val_loss: 2.3270 - val_acc: 0.0975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbed77d61d0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numofFeatures=train_data.shape[1]\n",
    "model=Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(numofFeatures,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=3, validation_data=(X_test,y_test),batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/3\n",
      "37500/37500 [==============================] - 2s 43us/step - loss: 2.0204 - acc: 0.2705 - val_loss: 1.8755 - val_acc: 0.3318\n",
      "Epoch 2/3\n",
      "37500/37500 [==============================] - 1s 32us/step - loss: 1.7971 - acc: 0.3647 - val_loss: 1.7369 - val_acc: 0.3864\n",
      "Epoch 3/3\n",
      "37500/37500 [==============================] - 1s 31us/step - loss: 1.7156 - acc: 0.3979 - val_loss: 1.6818 - val_acc: 0.4079\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbeac13eb38>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numofFeatures=train_data.shape[1]\n",
    "model=Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(numofFeatures,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=3, validation_data=(X_test,y_test),batch_size=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Varying Learning Rates and early stopping__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/20\n",
      "37500/37500 [==============================] - 7s 186us/step - loss: 1.8636 - acc: 0.3225 - val_loss: 1.7279 - val_acc: 0.3720\n",
      "Epoch 2/20\n",
      "37500/37500 [==============================] - 6s 173us/step - loss: 1.7157 - acc: 0.3839 - val_loss: 1.7025 - val_acc: 0.3868\n",
      "Epoch 3/20\n",
      "37500/37500 [==============================] - 7s 178us/step - loss: 1.6516 - acc: 0.4075 - val_loss: 1.6212 - val_acc: 0.4147\n",
      "Epoch 4/20\n",
      "37500/37500 [==============================] - 7s 173us/step - loss: 1.6140 - acc: 0.4238 - val_loss: 1.6026 - val_acc: 0.4260\n",
      "Epoch 5/20\n",
      "37500/37500 [==============================] - 7s 173us/step - loss: 1.5879 - acc: 0.4347 - val_loss: 1.5906 - val_acc: 0.4308\n",
      "Epoch 6/20\n",
      "37500/37500 [==============================] - 7s 182us/step - loss: 1.5641 - acc: 0.4366 - val_loss: 1.6454 - val_acc: 0.4161\n",
      "Epoch 7/20\n",
      "37500/37500 [==============================] - 6s 157us/step - loss: 1.5525 - acc: 0.4443 - val_loss: 1.5766 - val_acc: 0.4340\n",
      "Epoch 8/20\n",
      "37500/37500 [==============================] - 6s 156us/step - loss: 1.5360 - acc: 0.4506 - val_loss: 1.5755 - val_acc: 0.4334\n",
      "Epoch 9/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.5231 - acc: 0.4574 - val_loss: 1.5598 - val_acc: 0.4466\n",
      "Epoch 10/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.5152 - acc: 0.4603 - val_loss: 1.5555 - val_acc: 0.4460\n",
      "Epoch 11/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.4998 - acc: 0.4651 - val_loss: 1.5357 - val_acc: 0.4562\n",
      "Epoch 12/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.4900 - acc: 0.4673 - val_loss: 1.6187 - val_acc: 0.4295\n",
      "Epoch 13/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.4834 - acc: 0.4677 - val_loss: 1.5993 - val_acc: 0.4363\n",
      "Epoch 14/20\n",
      "37500/37500 [==============================] - 6s 147us/step - loss: 1.4736 - acc: 0.4712 - val_loss: 1.6153 - val_acc: 0.4345\n",
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/20\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 1.8748 - acc: 0.3211 - val_loss: 1.8032 - val_acc: 0.3416\n",
      "Epoch 2/20\n",
      "37500/37500 [==============================] - 6s 148us/step - loss: 1.7146 - acc: 0.3867 - val_loss: 1.6583 - val_acc: 0.4048\n",
      "Epoch 3/20\n",
      "37500/37500 [==============================] - 6s 153us/step - loss: 1.6504 - acc: 0.4075 - val_loss: 1.6061 - val_acc: 0.4239\n",
      "Epoch 4/20\n",
      "37500/37500 [==============================] - 7s 177us/step - loss: 1.6083 - acc: 0.4234 - val_loss: 1.6425 - val_acc: 0.4119\n",
      "Epoch 5/20\n",
      "37500/37500 [==============================] - 6s 173us/step - loss: 1.5783 - acc: 0.4359 - val_loss: 1.6050 - val_acc: 0.4262\n",
      "Epoch 6/20\n",
      "37500/37500 [==============================] - 7s 195us/step - loss: 1.5507 - acc: 0.4463 - val_loss: 1.5882 - val_acc: 0.4282\n",
      "Epoch 7/20\n",
      "37500/37500 [==============================] - 6s 169us/step - loss: 1.5351 - acc: 0.4512 - val_loss: 1.6245 - val_acc: 0.4210\n",
      "Epoch 8/20\n",
      "37500/37500 [==============================] - 6s 155us/step - loss: 1.5154 - acc: 0.4562 - val_loss: 1.5751 - val_acc: 0.4409\n",
      "Epoch 9/20\n",
      "37500/37500 [==============================] - 7s 175us/step - loss: 1.5052 - acc: 0.4599 - val_loss: 1.5498 - val_acc: 0.4470\n",
      "Epoch 10/20\n",
      "37500/37500 [==============================] - 7s 177us/step - loss: 1.4976 - acc: 0.4600 - val_loss: 1.5570 - val_acc: 0.4446\n",
      "Epoch 11/20\n",
      "37500/37500 [==============================] - 6s 155us/step - loss: 1.4818 - acc: 0.4680 - val_loss: 1.5330 - val_acc: 0.4496\n",
      "Epoch 12/20\n",
      "37500/37500 [==============================] - 6s 160us/step - loss: 1.4713 - acc: 0.4722 - val_loss: 1.5720 - val_acc: 0.4434\n",
      "Epoch 13/20\n",
      "37500/37500 [==============================] - 7s 175us/step - loss: 1.4637 - acc: 0.4765 - val_loss: 1.5865 - val_acc: 0.4443\n",
      "Epoch 14/20\n",
      "37500/37500 [==============================] - 6s 152us/step - loss: 1.4547 - acc: 0.4798 - val_loss: 1.5458 - val_acc: 0.4483\n",
      "Train on 37500 samples, validate on 12500 samples\n",
      "Epoch 1/20\n",
      "37500/37500 [==============================] - 6s 170us/step - loss: 1.8599 - acc: 0.3256 - val_loss: 1.7711 - val_acc: 0.3510\n",
      "Epoch 2/20\n",
      "37500/37500 [==============================] - 6s 156us/step - loss: 1.7040 - acc: 0.3879 - val_loss: 1.7206 - val_acc: 0.3752\n",
      "Epoch 3/20\n",
      "37500/37500 [==============================] - 6s 150us/step - loss: 1.6392 - acc: 0.4111 - val_loss: 1.6186 - val_acc: 0.4158\n",
      "Epoch 4/20\n",
      "37500/37500 [==============================] - 6s 149us/step - loss: 1.5927 - acc: 0.4300 - val_loss: 1.5807 - val_acc: 0.4294\n",
      "Epoch 5/20\n",
      "37500/37500 [==============================] - 6s 149us/step - loss: 1.5668 - acc: 0.4388 - val_loss: 1.5665 - val_acc: 0.4386\n",
      "Epoch 6/20\n",
      "37500/37500 [==============================] - 6s 151us/step - loss: 1.5399 - acc: 0.4488 - val_loss: 1.5648 - val_acc: 0.4372\n",
      "Epoch 7/20\n",
      "37500/37500 [==============================] - 6s 155us/step - loss: 1.5223 - acc: 0.4537 - val_loss: 1.5415 - val_acc: 0.4513\n",
      "Epoch 8/20\n",
      "37500/37500 [==============================] - 6s 153us/step - loss: 1.5067 - acc: 0.4601 - val_loss: 1.5446 - val_acc: 0.4521\n",
      "Epoch 9/20\n",
      "37500/37500 [==============================] - 6s 149us/step - loss: 1.4961 - acc: 0.4621 - val_loss: 1.6303 - val_acc: 0.4277\n",
      "Epoch 10/20\n",
      "37500/37500 [==============================] - 6s 149us/step - loss: 1.4841 - acc: 0.4684 - val_loss: 1.5929 - val_acc: 0.4400\n"
     ]
    }
   ],
   "source": [
    "results=np.zeros((0,2))\n",
    "lr_val=[0.001,0.005,0.01]\n",
    "#Monitor for 3 epochs if loss doesnt imporve\n",
    "\n",
    "for lr in lr_val:\n",
    "    numofFeatures=train_data.shape[1]\n",
    "    model=Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape=(numofFeatures,)))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "    sgd = optimizers.SGD(lr=lr_val[2], decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    history=model.fit(X_train,y_train,epochs=20, validation_data=(X_test,y_test),callbacks=[early_stopping_monitor])\n",
    "    \n",
    "    tmp=np.zeros((len(history.history['val_acc']),2))\n",
    "    tmp[:,0]=lr\n",
    "    tmp[:,1]=history.history['val_acc']\n",
    "    \n",
    "    results=np.vstack((results,tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.DataFrame(results,columns=['Learning Rate','Validation Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbed7858eb8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xt8nVWd7/HPN2nTa9oEGgq0SVukoqUCbUMBUQdUEB0FPDIO6qioczqOchgV5gw6IzOCOorH4ajwmjnowAGE08ELY8QigtJRFErTFigtLYbSS1qgLU1KL2nTpL/zx/Mk3Qk7Ozvd3bk03/frtV97P+tZz9prs+n+ZV2etRQRmJmZHa6Sga6AmZkNbQ4kZmZWEAcSMzMriAOJmZkVxIHEzMwK4kBiZmYFcSAxM7OCOJCYmVlBHEjMzKwgIwa6Av1h0qRJMX369IGuhpnZkLJs2bLtEVHVW75hEUimT59OfX39QFfDzGxIkbQhn3zu2jIzs4I4kJiZWUGKGkgkXSRpraQGSdfmyHeZpJBU2y29RtJuSdf0tUwzM+sfRQskkkqBW4B3A7OAD0malSVfOXAVsCRLMTcBD/S1TDMz6z/FbJHMBxoiYl1EtAILgUuy5LsBuBHYl5ko6VJgHbDqMMo0M7N+UsxAMgXYlHHcmKZ1kjQHqI6I+7uljwP+DvhKX8s0M7P+VcxAoixpndsxSioh6bq6Oku+rwA3RcTuvpTZJaO0QFK9pPpt27blWWUzM+urYt5H0ghUZxxPBbZkHJcDs4HFkgCOB+okXQycBVwm6UagAjgoaR+wrJcyO0XErcCtALW1td5P2Aadj/77EhqbWphaOYa7PnXWQFfH7LAVM5AsBWZKmgFsBi4HPtxxMiJ2ApM6jiUtBq6JiHrgrRnp/wTsjoibJY3IVabZUNLY1MIL2/cMdDXMCla0rq2IaAOuBB4EngXujYhVkq5PWx1HrMwjVWczM+u7oi6REhGLgEXd0q7rIe95PaT/U29lmpnZwPGd7WZmVpBhsWijmdmR5skShziQmJkdBk+WOMRdW2ZmVhAHEjMzK4gDiZmZFcSBxMzMCuJAYmZmBXEgMTOzgjiQmJlZQRxIzMysIA4kZmZWEAcSMzMriJdIGeK83o+ZDTQHkiHO6/2Y2UBz15aZmRWkqIFE0kWS1kpqkHRtjnyXSQpJtenxfElPpo+nJL0/I+96SSvTc/XFrL+ZmfWuaF1bkkqBW4ALgEZgqaS6iFjdLV85cBWwJCP5GaA2ItoknQA8Jenn6Va7AOdHxPZi1d3MzPJXzBbJfKAhItZFRCuwELgkS74bgBuBfR0JEbE3I2iMBqKI9TQzswIUM5BMATZlHDemaZ0kzQGqI+L+7hdLOkvSKmAl8OmMwBLAryQtk7SgOFU3M7N8FXPWlrKkdbYsJJUANwFXZLs4IpYAp0p6I3CHpAciYh9wbkRskXQc8JCkNRHx29e8eRJkFgDU1NQU/GHMzCy7YrZIGoHqjOOpwJaM43JgNrBY0nrgbKCuY8C9Q0Q8C+xJ8xIRW9LnrcB9JF1orxERt0ZEbUTUVlVVHZEPZGZmr1XMQLIUmClphqQy4HKgruNkROyMiEkRMT0ipgOPAxdHRH16zQgASdOAU4D1ksalg/NIGgdcSDIwb2ZmA6RoXVvpjKsrgQeBUuC2iFgl6XqgPiLqclz+FuBaSQeAg8BnImK7pJOA+yR11P2eiPhlsT6DmZn1rqh3tkfEImBRt7Tresh7Xsbru4C7suRZB5x+ZGtpZmaF8J3tZmZWEAcSMzMriAOJmZkVxIHEzMwK4kBiZmYFcSAxM7OCOJCYmVlBHEjMzKwgDiRmZlYQBxIzMyuIA4mZmRXEgcTMzAriQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCBFDSSSLpK0VlKDpGtz5LtMUnTs1y5pvqQn08dTkt7f1zLNzKx/FG2HREmlwC3ABUAjsFRSXUSs7pavHLgKWJKR/AxQm27XewLwlKSfA5FPmWZm1n+K2SKZDzRExLqIaAUWApdkyXcDcCOwryMhIvZGRFt6OJokgPSlTDMz6yfFDCRTgE0Zx41pWidJc4DqiLi/+8WSzpK0ClgJfDoNLL2WmXH9Akn1kuq3bdtW2CcxM7MeFTOQKEtadJ6USoCbgKuzXRwRSyLiVOBM4IuSRvdWZrfrb42I2oioraqq6nPlzcwsP8UMJI1AdcbxVGBLxnE5MBtYLGk9cDZQ1zHg3iEingX2pHl7K9PMzPpZr4EkHTQ/HEuBmZJmSCoDLgfqOk5GxM6ImBQR0yNiOvA4cHFE1KfXjEjffxpwCrC+tzLNzKz/5dMiaZD0LUmz+lJwOqZxJfAg8Cxwb0SsknS9pIt7ufwtJDO1ngTuAz4TEdt7KrMv9TIzsyMrn+m/p5H85f+DdFzjNmBhRLza24URsQhY1C3tuh7ynpfx+i7grnzLNDOzgdNriyQidkXE9yPizcD/BP4ReFHSHZJOLnoNzcxsUMtrjETSxZLuA74DfBs4Cfg5bhmYmQ17+XRt/RF4BPhWRPwhI/3Hkt5WnGqZmdlQkdcYSUTsznYiIq46wvUxM7MhJp9ZW7dIqug4kFQp6bYi1snMzIaQfALJaRHR3HEQEU3AnOJVyWx4aD+YLMoQkXVxBrMhI59AUiKpsuNA0jEUcdVgs6Pd4rVbufjmR9m4Yy8AjU0t/PDxDQ4oNmTlExC+DfxB0o/T4z8Dvla8KpkdvX75zEv89Q+XdVkgru1g8A//+Qxbd+3nCxe8fsDqZna48rmP5E7gMuBlYCvw39IbBs2sD9oPBjfcvzr7KqPALY808PKr+3o4azZ45dVFlS5tso1kbxAk1UTExqLWzGyAHGg/SMuBdva1trO3tZ2WA8nzvgPttLS2szc915HeciA5t7e1jZbWg4dep/lbDiSPV1va2NlyoMf3bT8Y3P34Bj5/weuRsi10bTY49RpI0nWxvg2cSNIimUayztWpxa2a5bJpx15+unwz23btB5Ifv+Gg/WAkP+gZP9J7W5PX+zJ+2JPzyQ975+sD7bQcONj5Ott1+w60c6B94MYqvvubBn64ZCNzqiuYO62SOTUVnD61gnGjPCxpg1c+/3feQLLE+8MRMUfS+cCHilsty+XOx9bzlbrVtGcMzjY2tXDnY+v52DnTB6paRAT72w52/tXe0tr1L/LOH/PWg+xtbesMCHszf8xb21/zl3xm2v62oRMwx4wsZWxZKaPT5xEl4tmXdvV63Y49rfx6zVZ+vWYrAKUl4g3HlzO3ppK50yqYW1NJzTFj3WqxQSOfQHIgIl6RVCKpJCIekfTNotfMsnp83Stc97PsCx5f97NVvH5yOWefdOxrzkUEB9qjyw905495+sN+qIum/TVdO12vy+jm6XidPobKxKOyESWMLStlzMj0Ufba544gkBkQOtKTPCO6Xl92KO+oESVZf+g/e89yfvH0i1nrNGl8GW97fRVPbmxm3fY9nentB4NVW15l1ZZXuevxDZ1559RUJsGlpoLTplYwpuxwd3wwK0w+gaRZ0njgt8DdkrYCbb1cY0Vy++9fyHn+M3cvp+aYsa8NCAfaO+9bGOxGlCjrD3uXH/SO12WljB05gjFlJV1/3MtKGDNyxGuu63guLRmYv+a/fumb2NLcwoqNzV3ST5w4mjs/dRYnHzcegKY9razY1MTyDc0s39jEk5ua2dva3pl/++5WHlr9Mg+tfhlI/pu98YQJzK1JusTm1lQytXKMWy3WL/IJJJcALcDngY8AE4Hri1kp69kzm3Ov3r9jTys79rQW7f0lsv+gp89jMl+PzPzLvST9q31E1uszrxtZWsyNOwfWxLEj+fGn38yvn32ZL9z7FLv3tzFpfBkPX/0njC079M+xclwZb3/DZN7+hskAtLUfZO3Lu1i+sZkVG5pYvrGJ9a/s7czfdjBYuXknKzfv5I7HklZLVfmoJLDUVDJ3WiVvmjKR0SPdarEjL2cgSXdH/FlEvBM4CNzRL7WyHo3tpftCQMXYkYwZmf61nv6gd/lxz/irfWzZiF66b7p2//TUZWP5Ky0RF556PFXla9i9v43y0SO7BJFsRpSWcOqJEzn1xIl89OxpALyyez8rNjazbGMTyzc08XTjTloOHGq1bNu1nwdXvcyDq5JWy8hSMevEiV2Cy4kTR/v7tILl/L83Itol7ZU0MSJ29rVwSReRLD1fCvwgIr7RQ77LgB8BZ6Zb7V4AfAMoA1qBv42I36R5FwMnkLSSAC6MiK19rdtQ9Z43ncB3fv3HHs//zTtn8rl3+qa24eDY8aN456zJvHPWoVbLmpd2sTwNLMs2NrFpR0tn/gPtwVObmnlqUzO3/349AJMnjErHWZLAMnvKBEaNcKvF+iafrq19wEpJDwGdI4C9rfybtmZuAS4AGoGlkuoiYnW3fOXAVcCSjOTtwPsiYouk2SRb607JOP+RiKjPo+5HnSvePJ37VmzuXF4jU80xY/n4AM7asoE1orSE2VMmMnvKxM7Ze9t27U8Cy8YmVmxo5qnG5i4z315+dT8PPPMSDzzzEgBlpSWcOmVCRnCp4ISJYwbi49gQkk8g+UX66Kv5QENErAOQtJBkvGV1t3w3ADcC13QkRMSKjPOrgNGSRkXE/sOox1GlclwZP/r0OXz1F8/ywMoXaUsH0MeVlfKjT59D5biyAa6hDSZV5aN416nH865TjweS+42effFVlm1oYvnGZpZvaGJz86FWS2v7QVZsbGbFxmb+nWRix4kTRzNn2qEZYqeeOJGyEUfvOJb1Xa+BJCIOd1xkCrAp47gROCszg6Q5QHVE3C/pGrL7ALCiWxC5XVI78BPgq5FltTtJC4AFADU1NYf5EQanyRNG870PzWHnpbN5z3d+x+bmFo6bMJrJE0YPdNVskBtZWsJpU5Ppwp84N0nb+uq+tNXSzLINTazcvJPWjFbLlp372PL0i53TlstGlPCmKROZN62yc7zlOP+/N6zlc2f7C/Da5YEi4qTeLs2S1lmOpBLgJuCKHO99KvBN4MKM5I9ExOa0S+wnwEeBO7PU71bgVoDa2tqhMe+1jyaOGem/DK1gx00YzUWzT+Ci2ScA0Np2kFVbdiYtlo1NrNjQxJadh9YAa207yLINTSzb0NSZNqViTDrtuIJ50yp54wkTjurZd9ZVPl1btRmvR5Os/ntMHtc1AtUZx1OBLRnH5cBsYHE6a+R4oE7SxemA+1TgPuBjEfF8x0URsTl93iXpHpIutNcEEjM7PGUjSphTU8mcmko+xQwAXtzZ0nlPy/KNTaza/CqtGcvybG5uYXNzCz9/KvknPnpkCadNqWBOeif+3JpKqspHDcjnseLLp2vrlW5J/1vSo8B1vVy6FJgpaQawGbgc+HBGuTuBSR3H6Wysa9IgUkEyLvPFiPh9Rp4RQEVEbJc0Engv8HBvn8HMCnPCxDH86Wlj+NPTklbLvgPtrNryKis2NqXjLU28/Oqh3ud9Bw7yxPodPLF+R2da9TFjmJfODptbU8kbji9nhFstR4V8urbmZhyWkLRQynu7LiLaJF1JMuOqFLgtXUX4eqA+IupyXH4lcDLwZUlfTtMuJJk19mAaREpJgsj3e6uLmR1Zo0eWMm9aJfOmVfKXb02W4Nmycx/L06CyfGMzq7fs7LIA5qYdLWza0cJ/Ppm0WsaMLOW0qROZO62SeTXJApXHjnerZSjKd2OrDm3AC8AH8yk8IhYBi7qlZW3JRMR5Ga+/Cny1h2Ln5fPeZtZ/JDGlYgxTKsbwvtNPBJJWy8rNO7sEl47VqgFaDrSz5IUdLHnhUKtl+rFjmVtTmc4Sq+CUyW61DAX5dG2d3x8VMbOjy+iRpZw5/RjOnJ4MqUYEjU0tnTdMLt/YzOoXX+2yBtz6V/ay/pW9/HTFZiCZ1n56dUXnPS1zqis9xX0Qyqdr6+vAjRHRnB5XAldHxD8Uu3JmdvSQRPUxY6k+ZiyXnJHcX9zS2s7Tjc2dM8SWb2jilYy14va0tvOH51/hD88fGqo9adI45tQk3Wpzp1Uw87jyAVuE0xL5dG29OyK+1HEQEU2S3gM4kJhZQcaUlXLWScdyVrr1QUSwccfeNKgkwWXNS7u6tFrWbd/Duu17+MnyRgDGjxrBGdUVzK2pSLrEqiuZOHbkgHye4SqfQFKaeVe5pDGAR8TM7IiTxLRjxzHt2HG8f85UAPbsb+Ppxp0ZXWJNNO09tGXx7v1tPNqwnUcbtnemnXzc+C6LU55cNZ4St1qKJp9A8kPg15JuJ7mh8JN4FWAz6yfjRo3gnNcdyzmvO9RqWf/K3s6gsmxDE8+9vIvM7XYatu6mYetu7q1PWi3lo5NWy7x06vEZNRVMGO1Wy5GSz2D7jZKeBt5Jcrf6DRHxYNFrZmaWhSRmTBrHjEnj+MC8pNWye38bT21q7gwuKzY105zRatm1r43f/XE7v/vj9rQMmHnc+C4rH580aVzerZadew+wP2PJ/uEun8H2GcDiiPhlejxG0vSIWF/sypmZ5WP8qBGce/Ikzj05ucc5Ili3fQ/LNjSxIh1veW7rrs6toCPguZd389zLu1m4NFkScOKYkcypOXQn/unVEynv1mrZvb+Nr96/mp+u2Ny5Htnm5hbq1++gdno+C34cnfLp2voR8OaM4/Y07cyi1MjMrECSeF3VeF5XNZ4P1iYrNb2670Daakk2A1uxsYld+w7tGr6z5QCL125j8dptaRlwyuTyzjvxT586kS/9dCVLM9YYg2TtsY/8YAn3/tU5nF5d0X8fchDJJ5CMiIjO+XgR0SrJE7nNbEiZMHokb51ZxVtnVgFw8GDw/LbdXWaI/XHr7s78EbDmpV2seWkX9yzZmLPs/W0H+fZDz3HnJ+cX9TMMVvkEkm3pQop1AJIuIdl4ysxsyCopETMnlzNzcjl/fmay1cTOvQdYsSm5WXLFxiae3NjMrv1tvZSU+O1z29izv41xo/L5WT265POJPw3cLelmksH2TcDHilorM7MBMHHsSM475TjOO+U4ANoPBg1bk1bLzb9p6LIJWDatbQcZNwxvjshn1tbzwNmSxgNKl2+fXPyqmZkNrNISccrx5ZxyfDk7Ww7wjQfW9Jh32rFjqRimN0L2ZTW0UuDPJD0MLC9SfczMBqUP1lYzYXTPf3v/5VtPIt1badjJGUjSqb5/LulnwDPAv5Csylud6zozs6PNMePKuP0TZ3JslkUjF7ztJP7irKNrS+++6DGQSLobeI5kH5CbgelAU0QsjoiDPV1nZna0mjftGH73d+dz42WndbZOplaO4UvveeOwbY1A7hbJbKAJeBZYExHtZNm73cxsOBlbNoIP1lZ3bsLlvelzBJKIOJ1kA6sJwMOSfgeUSzo+38IlXSRpraQGSdfmyHeZpJBUmx5fIGmZpJXp89sz8s5L0xskfVfD+c8AM7NBIGcojYg1EXFdRJwCfB64E3hC0h96K1hSKXAL8G5gFvAhSbOy5CsHrgKWZCRvB94XEW8CPg7clXHuX4EFwMz0cVFvdTEzs+LJu00WEfURcTUwDfhiHpfMBxoiYl16Z/xC4JIs+W4AbgT2ZbzXiojYkh6uAkZLGiXpBGBCRDwWEUES2C7N9zOYmdmR1+fOvUj8Vx5Zp5DcvNihMU3rJGkOUB0R9+co5wPAinQ/lClpOT2WmVH2Akn1kuq3bduWR3XNzOxwFHOUKNvYRedgvaQS4Cbg6h4LkE4Fvgn8VT5ldkmMuDUiaiOitqqqKu9Km5lZ3xQzkDTS9X6TqcCWjONykplhiyWtB84G6jIG3KcC9wEfS++u7yhzao4yzcysn+WzH8koku6l6Zn5I+L6Xi5dCsxM9zPZDFwOfDjj+p3ApIz3WQxcExH1kiqAXwBfjIjfZ1zzoqRdks4mGZz/GPC93j6DmZkVTz4tkp+RDJK3AXsyHjlFRBtwJfAgyb0o90bEKknXS7q4l8uvBE4GvizpyfRxXHrur4EfAA3A88ADeXwGMzMrknxW/50aEYc1xTYiFgGLuqVd10Pe8zJef5VkKZZs+epJusTMzGwQyKdF8gdJbyp6TczMbEjKp0XyFuAKSS8A+0lmTkVEnFbUmpmZ2ZCQTyB5d9FrYWZmQ1avXVsRsQGoAN6XPirSNDMzs94DiaS/Ae4GjksfP5T0P4pdMTMzGxry6dr6FHBWROwBkPRN4DF8/4aZmZHfrC0B7RnH7WRfqsTMzIahfFoktwNLJN2XHl8K/HvxqmRmZkNJr4EkIv4lXb7kLSQtkU9ExIpiV8zMzIaGHgOJpAkR8aqkY4D16aPj3DERsaP41TMzs8EuV4vkHuC9wDK6LtWu9PikItbLzMyGiB4DSUS8N32e0X/VMTOzoSaf+0h+nU+amZkNT7nGSEYDY4FJkio5NOV3AnBiP9TNzMyGgFxjJH8FfI4kaCzjUCB5FbilyPUyM7MhoseurYj4Tjo+ck1EnBQRM9LH6RFxcz6FS7pI0lpJDZKuzZHvMkmRsc3usZIekbRb0s3d8i5Oy+y+4ZWZmQ2AfO4j+Z6k2cAsYHRG+p25rpNUStJyuYBkr/WlkuoiYnW3fOXAVSRb53bYB3yZZAOrbJtYfSTd4MrMzAZYPoPt/0iyrtb3gPOBG4HetsoFmA80RMS6iGgFFpJs2dvdDWmZ+zoSImJPRDyamWZmZoNTPmttXQa8A3gpIj4BnA6MyuO6KcCmjOPGNK2TpDlAdUTcn191O92edmt9WZLX/TIzG0D5BJKWiDgItEmaAGwlv5sRs/3Ad97YKKkEuAm4Op+KZvhIRLwJeGv6+GjWN5cWSKqXVL9t27Y+voWZmeUrn0BSL6kC+D7J7K3lwBN5XNcIVGccTwW2ZByXk4x/LJa0HjgbqOsYcO9JRGxOn3eR3H0/v4d8t0ZEbUTUVlVV5VFdMzM7HPkMtn8mfflvkn4JTIiIp/MoeykwU9IMYDNwOfDhjHJ3ApM6jtOFIa/JNYguaQTJDo3bJY0kWcLl4TzqYmZmRZLrhsS5uc5FxPJcBUdEm6QrgQeBUuC2iFgl6XqgPiLqcl2ftlImAGWSLgUuBDYAD6ZBpJQkiHw/VzlmZlZcuVok306fRwO1wFMk4x6nkUzVfUtvhUfEImBRt7Tresh7Xrfj6T0UO6+39zUzs/6T64bE8yPifJJWwNx0vGEeMAdo6K8KmpnZ4JbPYPsbImJlx0FEPAOcUbwqmZnZUJLPVrvPSvoB8EOS6bt/ATxb1FqZmdmQkU8g+QTw18DfpMe/Bf61aDUyM7MhJZ/pv/tIbhy8qfjVsb6aWjmmy7OZWX/LNf333oj4oKSVdN1qF4CIOK2oNbO83PWpswa6CmY2zOVqkXR0Zb23PypiZmZDU649219Mnzf0X3XMzGyoydW1tYssXVokNyVGREwoWq3MzGzIyNUiKe/PipiZ2dCUz/RfANItbTN3SNxYlBqZmdmQks8OiRdL+iPwAvBfwHrggSLXy8zMhoh8lki5gWSvkOciYgbJbom/L2qtzMxsyMgnkByIiFeAEkklEfEIXmvLzMxS+YyRNEsaT7I0yt2StgJtxa2WmZkNFfm0SC4BWoDPA78EngfeV8xKmZnZ0NFjIJF0s6Q3R8SeiGiPiLaIuCMivpt2dfVK0kWS1kpqkHRtjnyXSYqO/dolHSvpEUm7Jd3cLe88SSvTMr8rSfl+WDMzO/JytUj+CHxb0npJ35TUp3ERSaXALcC7gVnAhyTNypKvHLiKZNfFDvuALwPXZCn6X4EFwMz0cVFf6mVmZkdWrh0SvxMR5wB/AuwAbpf0rKTrJL0+j7LnAw0RsS4iWoGFJN1k3d0A3EgSPDree09EPJqZBiDpBGBCRDwWEQHcCVyaR13MzKxIeh0jiYgNEfHNiJgDfBh4P/ltbDUF2JRx3JimdZI0B6iOiPvzrO+UtJweyzQzs/7V66wtSSNJuo8uJ7mH5L+Ar+RRdraxi861uySVkOxxckU+Fc2nzC4ZpQUkXWDU1NT04S3M+of3krGjRa5FGy8APgT8KfAESdfUgojYk2fZjUB1xvFUYEvGcTkwG1icjpcfD9RJujgi6nOUOTVHmZ0i4lbgVoDa2tqswcZsIHkvGTta5Ora+hLwGPDGiHhfRNzdhyACsBSYKWmGpDKSFk1dx8mI2BkRkyJiekRMBx4HcgWRjqXtd0k6O52t9THgZ32ok5mZHWG5Vv89v5CCI6JN0pXAg0ApcFtErJJ0PVAfEXW5rpe0HpgAlEm6FLgwIlaT7B//f4ExJGt+ed0vM7MBlPfqv4cjIhYBi7qlXddD3vO6HU/vIV89SZeYmZkNAvnc2W5mZtYjBxIzMyuIA4mZmRXEgcTMzAriQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCAOJGZmVhAHEjMzK4gDiZmZFcSBxMzMCuJAYmZmBXEgMTOzgjiQmJlZQRxIzMysIEUNJJIukrRWUoOka3Pku0xSSKrNSPtiet1aSe/KSF8vaaWkJyX1uC2vmZn1j6LtkCipFLgFuABoBJZKqku3y83MVw5cBSzJSJtFssf7qcCJwMOSXh8R7WmW8yNie7HqbmZm+Stmi2Q+0BAR6yKiFVgIXJIl3w3AjcC+jLRLgIURsT8iXgAa0vLMzGyQKWYgmQJsyjhuTNM6SZoDVEfE/X24NoBfSVomacGRrbKZmfVV0bq2AGVJi86TUglwE3BFH689NyK2SDoOeEjSmoj47WsKSILMAoCampo+Vt3MzPJVzBZJI1CdcTwV2JJxXA7MBhZLWg+cDdSlA+49XhsRHc9bgfvoocsrIm6NiNqIqK2qqjoiH8jMzF6rmIFkKTBT0gxJZSSD53UdJyNiZ0RMiojpETEdeBy4OCLq03yXSxolaQYwE3hC0rh0cB5J44ALgWeK+BnMzKwXRevaiog2SVcCDwKlwG0RsUrS9UB9RNTluHaVpHuB1UAb8NmIaJc0GbhPUkfd74mIXxbrM5iZWe+KOUZCRCwCFnVLu66HvOd1O/4a8LVuaeuA049sLc3MrBC+s93MzAriQGJmZgVxIDEzs4I4kJiZWUEcSMzMrCAOJGZmVhAHEjMzK4gDiZmZFcSBxMzMCuJAYmZmBXEgMTOzgjiQmJlZQRxIzMzGawaHAAAHLElEQVSsIA4kZmZWEAcSMzMriAOJmZkVpKiBRNJFktZKapB0bY58l0mKdL/2jrQvptetlfSuvpZpZmb9o2g7JEoqBW4BLgAagaWS6iJidbd85cBVwJKMtFkke7yfCpwIPCzp9enpXss0M7P+U8wWyXygISLWRUQrsBC4JEu+G4AbgX0ZaZcACyNif0S8ADSk5eVbppmZ9ZNiBpIpwKaM48Y0rZOkOUB1RNyf57W9lmlmZv2rmIFEWdKi86RUAtwEXN2Ha3OW2aUAaYGkekn127Zty6O6ZmZ2OIoZSBqB6ozjqcCWjONyYDawWNJ64GygLh1w7+na3srsFBG3RkRtRNRWVVUV+FHMzKwnRRtsB5YCMyXNADaTDJ5/uONkROwEJnUcS1oMXBMR9ZJagHsk/QvJYPtM4AmSFkmPZZqZ9ZeplWO6PA9nRQskEdEm6UrgQaAUuC0iVkm6HqiPiLoc166SdC+wGmgDPhsR7QDZyizWZzAz68ldnzproKswaCgi6xDDUaW2tjbq6+sHuhpmZkOKpGURUdtbPt/ZbmZmBXEgMTOzgjiQmJlZQRxIzMysIA4kZmZWEAcSMzMryLCY/itpG7BhoOtRRJOA7QNdCTss/u6GtqP9+5sWEb0uDTIsAsnRTlJ9PnO9bfDxdze0+ftLuGvLzMwK4kBiZmYFcSA5Otw60BWww+bvbmjz94fHSMzMrEBukZiZWUEcSAYZSRdJWiupQdK1Wc6PkvQf6fklkqZnnPtimr5W0rsy0m+TtFXSM/3zKYavIn1/6yWtlPSkJC9j3Q8O93uUdKykRyTtlnRzf9d7wESEH4PkQbLHyvPASUAZ8BQwq1uezwD/lr6+HPiP9PWsNP8oYEZaTml67m3AXOCZgf6MR/OjiN/femDSQH++4fIo8HscB7wF+DRw80B/lv56uEUyuMwHGiJiXUS0AguBS7rluQS4I339Y+AdkpSmL4yI/RHxAtCQlkdE/BbY0R8fYJgryvdn/e6wv8eI2BMRjwL7+q+6A8+BZHCZAmzKOG5M07LmiYg2YCdwbJ7XWnEV6/sL4FeSlklaUIR6W1eFfI/DUjH3bLe+U5a07tPqesqTz7VWXMX6/s6NiC2SjgMekrQmbWVacRTyPQ5LbpEMLo1AdcbxVGBLT3kkjQAmknRb5XOtFVdRvr+I6HjeCtyHu7yKrZDvcVhyIBlclgIzJc2QVEYyiFfXLU8d8PH09WXAbyIZ5asDLk9nk8wAZgJP9FO9LXHEvz9J4ySVA0gaB1wIePZdcRXyPQ5PAz3a70fXB/Ae4DmSWSN/n6ZdD1ycvh4N/IhkMPYJ4KSMa/8+vW4t8O6M9P8HvAgcIPlL6lMD/TmP1seR/v5IZg49lT5WdZTpx6D+HteTtE52p//eZvV3/fv74TvbzcysIO7aMjOzgjiQmJlZQRxIzMysIA4kZmZWEAcSMzMriAOJDUuSdvfz+/1A0qwjVFZ7uhLwM5J+Lqmil/wVkj5zJN7bLBtP/7VhSdLuiBh/BMsbEcmaS0WXWXdJdwDPRcTXcuSfDtwfEbP7o342/LhFYpaSVCXpJ5KWpo9z0/T5kv4gaUX6fEqafoWkH0n6OcmiiudJWizpx5LWSLo7XdmXNL02fb1b0tckPSXpcUmT0/TXpcdLJV2fZ6vpMdIFBSWNl/RrScvT/Us6Vqz9BvC6tBXzrTTv36bv87SkrxzB/4w2DDmQmB3yHeCmiDgT+ADwgzR9DfC2iJgDXAd8PeOac4CPR8Tb0+M5wOdI9hc5CTg3y/uMAx6PiNOB3wL/PeP9v5O+f6/rpEkqBd7BoeU79gHvj4i5wPnAt9NAdi3wfEScERF/K+lCkiVY5gNnAPMkva239zPriVf/NTvkncCstBEBMCFd52oicIekmSQrvI7MuOahiMhcrO+JiGgEkPQkMB14tNv7tAL3p6+XARekr88BLk1f3wP8rx7qOSaj7GXAQ2m6gK+nQeEgSUtlcpbrL0wfK9Lj8SSBxSsK22FxIDE7pAQ4JyJaMhMlfQ94JCLen443LM44vadbGfszXreT/d/YgTg0ONlTnlxaIuIMSRNJAtJnge8CHwGqgHkRcUDSepI1oboT8M8R8X/6+L5mWblry+yQXwFXdhxIOiN9ORHYnL6+oojv/zhJlxokK87mFBE7gauAaySNJKnn1jSInA9MS7PuAsozLn0Q+KSkjgH7KeleJ2aHxYHEhquxkhozHl8g+VGuTQegV5Psuw1wI/DPkn5Psp93sXwO+IKkJ4ATSHbdyykiVpCsDHw5cDdJ/etJWidr0jyvAL9Ppwt/KyJ+RdJ19piklSRbxZZnfQOzPHj6r9kgIWksSbdVSLoc+FBEdN8r3GzQ8RiJ2eAxD7g5nWnVDHxygOtjlhe3SMzMrCAeIzEzs4I4kJiZWUEcSMzMrCAOJGZmVhAHEjMzK4gDiZmZFeT/A8b36YKmHy/JAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "sns.pointplot(x=\"Learning Rate\",y=\"Validation Accuracy\",data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Testing Accuracy__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-414dbd3e2c6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumofFeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumofFeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "numofFeatures=train_data.shape[1]\n",
    "model=Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(numofFeatures,)))\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(patience=3)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.005, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train,y_train,epochs=20, validation_data=(X_test,y_test),callbacks=[early_stopping_monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
